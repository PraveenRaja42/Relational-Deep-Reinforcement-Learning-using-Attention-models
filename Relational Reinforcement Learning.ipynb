{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from random import shuffle\n",
    "from torch import nn\n",
    "from tensorboardX import SummaryWriter\n",
    "from collections import deque\n",
    "from einops import rearrange, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(210, 160, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"Breakout-v4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadRelationalModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadRelationalModule, self).__init__()\n",
    "        self.conv1_ch = 16\n",
    "        self.conv2_ch = 20\n",
    "        self.conv3_ch = 24\n",
    "        self.conv4_ch = 30\n",
    "        self.H = 28\n",
    "        self.W = 26\n",
    "        self.node_size = 64\n",
    "        self.len_hid = 100\n",
    "        self.out_dim = 4\n",
    "        self.ch_in = 3\n",
    "        self.sp_coord_dim = 2\n",
    "        self.N =  176\n",
    "        self.n_heads = 3\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(self.ch_in,self.conv1_ch,kernel_size=(4,4),padding=0).cuda()\n",
    "        self.pool = nn.MaxPool2d(2,2).cuda()\n",
    "        self.conv2 = nn.Conv2d(self.conv1_ch,self.conv2_ch,kernel_size=(4,4),padding=0).cuda()\n",
    "        self.conv3 = nn.Conv2d(self.conv2_ch,self.conv3_ch,kernel_size=(4,4),padding=0).cuda()\n",
    "        self.conv4 = nn.Conv2d(self.conv3_ch,self.conv4_ch,kernel_size=(4,4),padding=0).cuda()\n",
    "        \n",
    "        self.proj_shape = (self.conv4_ch+self.sp_coord_dim,self.n_heads * self.node_size)\n",
    "        self.k_proj = nn.Linear(*self.proj_shape).cuda()\n",
    "        self.q_proj = nn.Linear(*self.proj_shape).cuda()\n",
    "        self.v_proj = nn.Linear(*self.proj_shape).cuda()\n",
    "        \n",
    "        self.k_lin = nn.Linear(self.node_size,self.N).cuda()\n",
    "        self.q_lin = nn.Linear(self.node_size,self.N).cuda()\n",
    "        self.a_lin = nn.Linear(self.N,self.N).cuda()\n",
    "        \n",
    "        self.node_shape = (self.n_heads, self.N,self.node_size)\n",
    "        self.k_norm = nn.LayerNorm(self.node_shape, elementwise_affine=True).cuda()\n",
    "        self.q_norm = nn.LayerNorm(self.node_shape, elementwise_affine=True).cuda()\n",
    "        self.v_norm = nn.LayerNorm(self.node_shape, elementwise_affine=True).cuda()\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.n_heads * self.node_size, self.node_size).cuda()\n",
    "        self.norm = nn.LayerNorm([self.N,self.node_size], elementwise_affine=False).cuda()\n",
    "        self.linear2 = nn.Linear(self.node_size, self.out_dim).cuda()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        N, Cin, H, W = x.shape\n",
    "        #x = self.pool(torch.relu(self.conv1(x)))\n",
    "        #x = self.pool(torch.relu(self.conv2(x)))\n",
    "        #x = self.pool(torch.relu(self.conv3(x)))\n",
    "        #x = self.pool(torch.relu(self.conv4(x)))\n",
    "        \n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.conv_map = x.cpu().clone()\n",
    "        _,_,cH,cW = x.shape\n",
    "        xcoords = torch.arange(cW).repeat(cH,1).float().cuda() / cW\n",
    "        ycoords = torch.arange(cH).repeat(cW,1).transpose(1,0).float().cuda() / cH\n",
    "        spatial_coords = torch.stack([xcoords,ycoords],dim=0)\n",
    "        spatial_coords = spatial_coords.unsqueeze(dim=0)\n",
    "        spatial_coords = spatial_coords.repeat(N,1,1,1)\n",
    "        x = torch.cat([x,spatial_coords],dim=1)\n",
    "        x = x.permute(0,2,3,1)\n",
    "        x = x.flatten(1,2)\n",
    "        \n",
    "        K = rearrange(self.k_proj(x), \"b n (head d) -> b head n d\", head=self.n_heads)\n",
    "        K = self.k_norm(K)\n",
    "        \n",
    "        Q = rearrange(self.q_proj(x), \"b n (head d) -> b head n d\", head=self.n_heads)\n",
    "        Q = self.q_norm(Q)\n",
    "        \n",
    "        V = rearrange(self.v_proj(x), \"b n (head d) -> b head n d\", head=self.n_heads)\n",
    "        V = self.v_norm(V)\n",
    "        \n",
    "        A = torch.nn.functional.elu(self.q_lin(Q) + self.k_lin(K))\n",
    "        A = self.a_lin(A)\n",
    "        A = torch.nn.functional.softmax(A,dim=3)\n",
    "        with torch.no_grad():\n",
    "            self.att_map = A.cpu().clone()\n",
    "        E = torch.einsum('bhfc,bhcd->bhfd',A,V)\n",
    "        \n",
    "        E = rearrange(E, 'b head n d -> b n (head d)')\n",
    "        \n",
    "        E = self.linear1(E)\n",
    "        E = torch.relu(E)\n",
    "        \n",
    "        E = E.max(dim=1)[0]\n",
    "        y = self.linear2(E)\n",
    "        y = torch.nn.functional.elu(y)\n",
    "        return y\n",
    "            \n",
    "                      \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def ress(env, input_size=(100,80),to_gray=False):\n",
    "    return resize(env, input_size, anti_aliasing=True).max(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = env.reset()\n",
    "xy = ress(x)\n",
    "xy.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x274d71bfbc8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ress(env.render(\"rgb_array\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def prepare_state(x, new_size=(100,100)):\n",
    "    \n",
    "    x = resize(x, new_size, anti_aliasing=True).max(axis=2)\n",
    "    ns = torch.from_numpy(x).float().permute(2,0,1).unsqueeze(dim=0)\n",
    "    maxv = ns.flatten().max()\n",
    "    ns = ns / maxv\n",
    "    return ns\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_state(x, new_size=(100,80),N=3):\n",
    "    \n",
    "    x = resize(x, new_size, anti_aliasing=True).max(axis=2)\n",
    "    ns = torch.from_numpy(x).float()\n",
    "    maxv = ns.repeat((N,1,1))\n",
    "    return maxv.unsqueeze(dim=0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 100, 80])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = prepare_state(env.reset())\n",
    "state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,cH,cW = state.shape\n",
    "xcoords = torch.arange(cW).repeat(cH,1).float().cuda() / cW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0152, 0.0303,  ..., 0.9545, 0.9697, 0.9848],\n",
       "        [0.0000, 0.0152, 0.0303,  ..., 0.9545, 0.9697, 0.9848],\n",
       "        [0.0000, 0.0152, 0.0303,  ..., 0.9545, 0.9697, 0.9848],\n",
       "        ...,\n",
       "        [0.0000, 0.0152, 0.0303,  ..., 0.9545, 0.9697, 0.9848],\n",
       "        [0.0000, 0.0152, 0.0303,  ..., 0.9545, 0.9697, 0.9848],\n",
       "        [0.0000, 0.0152, 0.0303,  ..., 0.9545, 0.9697, 0.9848]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(replay,size):\n",
    "    \n",
    "    batch_ids = np.random.randint(0, len(replay),size)\n",
    "    batch = [replay[x] for x in batch_ids]\n",
    "    state_batch = torch.cat([s for (s,a,r,s2,d) in batch],)\n",
    "    action_batch = torch.Tensor([a for (s,a,r,s2,d) in batch]).long()\n",
    "    reward_batch = torch.Tensor([r for (s,a,r,s2,d) in batch])\n",
    "    state2_batch = torch.cat([s2 for (s,a,r,s2,d) in batch],dim=0)\n",
    "    done_batch = torch.Tensor([d for (s,a,r,s2,d) in batch])\n",
    "    \n",
    "    return state_batch, action_batch, reward_batch, state2_batch, done_batch\n",
    "\n",
    "def get_qtarget(qvals,r,df,done):\n",
    "    \n",
    "    maxqvals = torch.max(qvals,dim=1)[0]\n",
    "    targets = r + (1-done) * df * maxqvals\n",
    "    return targets\n",
    "\n",
    "def get_qtarget_ddqn(qvals, r, df, done):\n",
    "    \n",
    "    targets = r + (1-done) * df * qvals\n",
    "    return targets\n",
    "\n",
    "def lossfn(pred,targets,actions):\n",
    "    loss = torch.mean(torch.pow(\\\n",
    "                               targets.detach()-\\\n",
    "                               pred.gather(dim=1,index=actions.unsqueeze(dim=1)).squeeze(),2),dim=0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def update_replay_old(replay,exp,replay_size):\n",
    "    r = exp[2]\n",
    "    N = 1\n",
    "    if r > 0:\n",
    "        N = 50\n",
    "    for i in range(N):\n",
    "        if len(replay) < replay_size:\n",
    "            replay.append(exp)\n",
    "        else:\n",
    "            rid = np.random.randint(0,len(replay))\n",
    "            replay[rid] = exp\n",
    "    return replay\n",
    "  \n",
    "def update_replay(replay,exp,replay_size):\n",
    "  r = exp[2]\n",
    "  N = 1\n",
    "  if r > 0:\n",
    "      N = 50\n",
    "  for i in range(N):\n",
    "      replay.append(exp)\n",
    "  return replay    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x,tau=1.9):\n",
    "    z = torch.exp(tau*x) / torch.exp(tau*x).sum()\n",
    "    return z\n",
    "\n",
    "def logsoftmax(x,tau=1.9):\n",
    "    z = torch.log(softmax(x,tau=tau))\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_map = {\n",
    "    0:0,\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:3,\n",
    "}    \n",
    "    #5:5,\n",
    "    #6:6,\n",
    "    #7:7,\n",
    "    #8:8,\n",
    "    #9:9,\n",
    "    #10:10,\n",
    "    #11:11,\n",
    "    #12:12,\n",
    "    #13:13,\n",
    "    #14:14,\n",
    "    #15:15,\n",
    "    #16:16,\n",
    "    #17:17,\n",
    "    #18:18,   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Alien-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = prepare_state(env.reset())\n",
    "GWagent = MultiHeadRelationalModule().cuda() #RelationalModule\n",
    "Tnet = MultiHeadRelationalModule().cuda()\n",
    "maxsteps = 400\n",
    "\n",
    "env.max_steps = maxsteps\n",
    "env.env.max_steps = maxsteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1405, -0.3122,  0.1642,  0.0135]], device='cuda:0',\n",
       "       grad_fn=<EluBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GWagent(state.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n",
      "shit!!!GameLost!!!!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-61e1eef92391>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mq_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGWagent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mastar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate2_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mastar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_qtarget_ddqn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdone_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ab1e2813ea74>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mxcoords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mycoords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mspatial_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxcoords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mycoords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mspatial_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspatial_coords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "renders = deque(maxlen=1500)\n",
    "#writer = SummaryWriter(log_dir='logs/exp')\n",
    "epochs = 50000\n",
    "replay_size = 9000\n",
    "batch_size = 50\n",
    "lr = 0.0005\n",
    "gamma = 0.99\n",
    "replay = deque(maxlen=replay_size)\n",
    "opt = torch.optim.Adam(params=GWagent.parameters(),lr=lr)\n",
    "losses = []\n",
    "avg_rewards = []\n",
    "state = prepare_state(env.reset())\n",
    "renders.append(env.render(mode='rgb_array'))\n",
    "eps = 0.3\n",
    "update_freq = 100\n",
    "\n",
    "ep_len = 0\n",
    "for i in range(epochs):\n",
    "    \n",
    "    ep_len += 1\n",
    "    pred = GWagent(state.cuda()).cpu()\n",
    "    action = int(torch.argmax(pred).detach().numpy())\n",
    "    if np.random.rand() < eps:\n",
    "        action = int(torch.randint(0,4,size=(1,)).squeeze())\n",
    "        \n",
    "    action_d = action_map[action]\n",
    "    state2, reward, done, info = env.step(action)\n",
    "    reward = -0.01 if reward == 0 else reward\n",
    "    renders.append(env.render(mode='rgb_array'))\n",
    "    state2 = prepare_state(state2)\n",
    "    exp = (state,action,reward,state2,done)\n",
    "    \n",
    "    replay = update_replay(replay,exp,replay_size)\n",
    "    \n",
    "    if done:\n",
    "        state = prepare_state(env.reset())\n",
    "        avg_rewards.append(ep_len)\n",
    "        ep_len = 0\n",
    "        if reward > 0:\n",
    "            print(\"Game won!!!!!hellyeah!!!\")\n",
    "        else:\n",
    "            print(\"shit!!!GameLost!!!!\")\n",
    "    \n",
    "    else:\n",
    "        state = state2\n",
    "    if len(replay) > batch_size:\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        state_batch, action_batch, reward_batch, state2_batch, done_batch = get_minibatch(replay,batch_size)\n",
    "        \n",
    "        q_pred = GWagent(state_batch.cuda()).cpu()\n",
    "        astar = torch.argmax(q_pred,dim=1)\n",
    "        qs = Tnet(state2_batch.cuda()).cpu().gather(dim=1,index=astar.unsqueeze(dim=1)).squeeze()\n",
    "        \n",
    "        targets = get_qtarget_ddqn(qs.detach(),reward_batch.detach(),gamma,done_batch)\n",
    "        \n",
    "        loss = lossfn(q_pred,targets.detach(),action_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(GWagent.parameters(),max_norm=1.0)\n",
    "        losses.append(loss.detach().numpy())\n",
    "        #writer.add_scalar('Loss', loss.detach().numpy(),i)\n",
    "        opt.step()\n",
    "        \n",
    "    if i % update_freq == 0:\n",
    "        Tnet.load_state_dict(GWagent.state_dict())\n",
    "        \n",
    "losses = np.array(losses)\n",
    "avg_rewards = np.array(avg_rewards)\n",
    "renders = np.stack(renders)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"test2.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "from IPython.display import Video\n",
    "imageio.mimwrite('test2.mp4', renders, fps=15)\n",
    "Video('test2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x274fcf53888>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_ = env.reset()\n",
    "state = prepare_state(state_)\n",
    "GWagent(state.cuda()).cpu()\n",
    "plt.imshow(env.render('rgb_array'))\n",
    "plt.imshow(state[0].permute(1,2,0).detach().numpy())\n",
    "head, node = 1, 36\n",
    "plt.imshow(GWagent.att_map[0][head][node].view(16,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
